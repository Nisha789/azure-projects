{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkPool",
              "statement_id": 2,
              "statement_ids": [
                2
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "0",
              "normalized_state": "finished",
              "queued_time": "2025-02-27T05:45:07.0295968Z",
              "session_start_time": "2025-02-27T05:45:07.0309618Z",
              "execution_start_time": "2025-02-27T05:48:44.0055548Z",
              "execution_finish_time": "2025-02-27T05:48:44.1688355Z",
              "parent_msg_id": "01d77b2c-146a-443b-acd1-16083d6a0e9d"
            },
            "text/plain": "StatementMeta(sparkPool, 0, 2, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "base_path = \"abfss://fintechadls@fintechadls.dfs.core.windows.net/bronze/fintech/\"\n",
        "output_base_path = \"abfss://fintechadls@fintechadls.dfs.core.windows.net/silver/fintech/\"\n",
        "\n",
        "spark.conf.set(\"spark.databricks.delta.schema.autoMerge.enabled\",\"true\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkPool",
              "statement_id": 3,
              "statement_ids": [
                3
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "0",
              "normalized_state": "finished",
              "queued_time": "2025-02-27T05:48:09.2855554Z",
              "session_start_time": null,
              "execution_start_time": "2025-02-27T05:48:44.2686869Z",
              "execution_finish_time": "2025-02-27T05:48:44.4489853Z",
              "parent_msg_id": "abc01d38-329a-4d4b-97a9-098c33c00187"
            },
            "text/plain": "StatementMeta(sparkPool, 0, 3, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformation for Accounts dataset\n",
        "def transform_accounts():\n",
        "    df = spark.read.parquet(f\"{base_path}Accounts/Accounts.parquet\")\n",
        "    # Example transformation: Calculate account age in years\n",
        "    df_transformed = df.withColumn(\"AccountAgeYears\", round(datediff(current_date(),col(\"OpenDate\")) / 365.25,2))\n",
        "    df_transformed.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}Accounts/\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkPool",
              "statement_id": 4,
              "statement_ids": [
                4
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "0",
              "normalized_state": "finished",
              "queued_time": "2025-02-27T05:51:52.1787608Z",
              "session_start_time": null,
              "execution_start_time": "2025-02-27T05:51:52.2615237Z",
              "execution_finish_time": "2025-02-27T05:51:52.4096229Z",
              "parent_msg_id": "35c5fde2-5fa5-4b42-bf06-7f50306df2f3"
            },
            "text/plain": "StatementMeta(sparkPool, 0, 4, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_customers():\n",
        "    df = spark.read.parquet(f\"{base_path}Customers/Customers.parquet\")\n",
        "    # Example transformation: Create a full name column and mask the email address\n",
        "    df_transformed = df.withColumn(\"FullName\",concat_ws(\" \",col(\"Firstname\"),col(\"LastName\")))\\\n",
        "                        .withColumn(\"MaskedEmail\", concat(lit(\"***@\"),substring_index(col(\"Email\"),\"@\",-1)))\n",
        "    df_transformed.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}Customers/\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkPool",
              "statement_id": 5,
              "statement_ids": [
                5
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "0",
              "normalized_state": "finished",
              "queued_time": "2025-02-27T05:55:59.6661177Z",
              "session_start_time": null,
              "execution_start_time": "2025-02-27T05:55:59.7560466Z",
              "execution_finish_time": "2025-02-27T05:55:59.9108617Z",
              "parent_msg_id": "337589e4-3287-47d7-baf0-fc37edd2acd0"
            },
            "text/plain": "StatementMeta(sparkPool, 0, 5, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformation for Loans dataset with explicit casting\n",
        "def transform_loans():\n",
        "    df = spark.read.parquet(f\"{base_path}Loans/Loans.parquet\")\n",
        "    # Example transformation: Calculate total interest with explicit casting to match the Delta table\n",
        "    df_transformed = df.withColumn(\"TotalInterest\", \n",
        "                                   (col(\"LoanAmount\") * col(\"InterestRate\") / 100).cast(\"decimal(28,8)\")) \\\n",
        "                       .withColumn(\"LoanDurationYears\", \n",
        "                                   round(datediff(col(\"LoanEndDate\"), col(\"LoanStartDate\")) / 365.25, 2))\n",
        "    df_transformed.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}Loans/\")\n",
        "\n",
        "# Transformation for Payments dataset\n",
        "def transform_payments():\n",
        "    df = spark.read.parquet(f\"{base_path}Payments/Payments.parquet\")\n",
        "    # Example transformation: Calculate days since last payment\n",
        "    df_transformed = df.withColumn(\"DaysSinceLastPayment\", \n",
        "                                   datediff(current_date(), col(\"PaymentDate\")))\n",
        "    df_transformed.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}Payments/\")\n",
        "\n",
        "# Transformation for Transactions dataset\n",
        "def transform_transactions():\n",
        "    df = spark.read.parquet(f\"{base_path}Transactions/Transactions.parquet\")\n",
        "    # Example transformation: Categorize transaction types\n",
        "    df_transformed = df.withColumn(\"TransactionCategory\", \n",
        "                                   when(col(\"TransactionType\") == \"Deposit\", \"Income\")\n",
        "                                   .when(col(\"TransactionType\") == \"Withdrawal\", \"Expense\")\n",
        "                                   .otherwise(\"Other\"))\n",
        "    df_transformed.write.format(\"delta\").mode(\"overwrite\").save(f\"{output_base_path}Transactions/\")\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkPool",
              "statement_id": 6,
              "statement_ids": [
                6
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "0",
              "normalized_state": "finished",
              "queued_time": "2025-02-27T05:56:21.6622276Z",
              "session_start_time": null,
              "execution_start_time": "2025-02-27T05:56:21.7351253Z",
              "execution_finish_time": "2025-02-27T05:56:21.8855775Z",
              "parent_msg_id": "9f23b6df-1d8d-4513-affa-8fbbe1bab652"
            },
            "text/plain": "StatementMeta(sparkPool, 0, 6, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Process each table\n",
        "transform_accounts()\n",
        "transform_customers()\n",
        "transform_loans()\n",
        "transform_payments()\n",
        "transform_transactions()\n",
        "\n",
        "print(\"Bronze To Silver Completed !!\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkPool",
              "statement_id": 7,
              "statement_ids": [
                7
              ],
              "state": "finished",
              "livy_statement_state": "cancelled",
              "spark_jobs": null,
              "session_id": "0",
              "normalized_state": "cancelled",
              "queued_time": "2025-02-27T05:56:33.7457421Z",
              "session_start_time": null,
              "execution_start_time": "2025-02-27T05:56:34.568725Z",
              "execution_finish_time": "2025-02-27T05:56:36.3937361Z",
              "parent_msg_id": "76656fbc-5c87-4a46-ac1e-bbe117ba13cc"
            },
            "text/plain": "StatementMeta(sparkPool, 0, 7, Finished, Cancelled, Cancelled)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}